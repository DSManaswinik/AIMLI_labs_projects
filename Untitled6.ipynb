{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN01S9YtQe65z/Qj7T+bJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSManaswinik/AIMLI_labs_projects/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtXI3nNfBzYC"
      },
      "outputs": [],
      "source": [
        "\n",
        "Open In Colab\n",
        "Module 2: Appreciating, Interpreting and Visualizing Data\n",
        "Project\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "we wil be performing a simple Exploratory Data Anaysis for this project. We will use the methods we learned in the tutorials to have a basic understanding of the dataset. So first we will start with the heart dataset available from kaggle. the infomration about the columns of the dataset is given below:\n",
        "-age\n",
        "-sex\n",
        "-chest pain type (4 values)\n",
        "-resting blood pressure\n",
        "-serum cholestoral in mg/dl\n",
        "-fasting blood sugar > 120 mg/dl\n",
        "-resting electrocardiographic results (values 0,1,2)\n",
        "-maximum heart rate achieved\n",
        "-exercise induced angina\n",
        "-oldpeak = ST depression induced by exercise relative to rest\n",
        "-the slope of the peak exercise ST segment\n",
        "-number of major vessels (0-3) colored by flourosopy\n",
        "-:thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
        "\n",
        "Fill in the portions that says \"to do\"\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving heart.csv to heart.csv\n",
        "\n",
        "data = pd.read_csv(\"heart.csv\")\n",
        "data.head()\n",
        "\n",
        "age\tsex\tcp\ttrestbps\tchol\tfbs\trestecg\tthalach\texang\toldpeak\tslope\tca\tthal\ttarget\n",
        "0\t63\t1\t3\t145\t233\t1\t0\t150\t0\t2.3\t0\t0\t1\t1\n",
        "1\t37\t1\t2\t130\t250\t0\t1\t187\t0\t3.5\t0\t0\t2\t1\n",
        "2\t41\t0\t1\t130\t204\t0\t0\t172\t0\t1.4\t2\t0\t2\t1\n",
        "3\t56\t1\t1\t120\t236\t0\t1\t178\t0\t0.8\t2\t0\t2\t1\n",
        "4\t57\t0\t0\t120\t354\t0\t1\t163\t1\t0.6\t2\t0\t2\t1\n",
        "\n",
        "data.shape\n",
        "\n",
        "(303, 14)\n",
        "\n",
        "data.columns\n",
        "\n",
        "\n",
        "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
        "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
        "      dtype='object')\n",
        "Data preparation\n",
        "\n",
        "\n",
        "## we will be comparing rest of the parameters/columns present in the data with respect to precence or absece of heart disease\n",
        "data['target'] = data.target.replace({1: \"Disease\", 0: \"No_disease\"})\n",
        "data['sex'] = data.sex.replace({1: \"Male\", 0: \"Female\"})\n",
        "data['cp'] = data.cp.replace({1: \"typical_angina\",\n",
        "                          2: \"atypical_angina\",\n",
        "                          3:\"non-anginal pain\",\n",
        "                          4: \"asymtomatic\"})\n",
        "data['exang'] = data.exang.replace({1: \"Yes\", 0: \"No\"})\n",
        "data['slope'] = data.cp.replace({1: \"upsloping\",\n",
        "                          2: \"flat\",\n",
        "                          3:\"downsloping\"})\n",
        "data['thal'] = data.thal.replace({1: \"fixed_defect\", 2: \"reversable_defect\", 3:\"normal\"})\n",
        "\n",
        "\n",
        "data.head()\n",
        "\n",
        "age\tsex\tcp\ttrestbps\tchol\tfbs\trestecg\tthalach\texang\toldpeak\tslope\tca\tthal\ttarget\n",
        "0\t63\tMale\tnon-anginal pain\t145\t233\t1\t0\t150\tNo\t2.3\tnon-anginal pain\t0\tfixed_defect\tDisease\n",
        "1\t37\tMale\tatypical_angina\t130\t250\t0\t1\t187\tNo\t3.5\tatypical_angina\t0\treversable_defect\tDisease\n",
        "2\t41\tFemale\ttypical_angina\t130\t204\t0\t0\t172\tNo\t1.4\ttypical_angina\t0\treversable_defect\tDisease\n",
        "3\t56\tMale\ttypical_angina\t120\t236\t0\t1\t178\tNo\t0.8\ttypical_angina\t0\treversable_defect\tDisease\n",
        "4\t57\tFemale\t0\t120\t354\t0\t1\t163\tYes\t0.6\t0\t0\treversable_defect\tDisease\n",
        "First, lets look at the difference in the number of samples with and without disease using a barplot.\n",
        "\n",
        "\n",
        "sns.barplot(data['target'].value_counts())\n",
        "plt.title('Heart Disease Classes')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "## we can plot the same barplots usng the pandas inbuilt plotting functions.\n",
        "data['target'].value_counts().plot(kind='bar').set_title('Heart Disease Classes')\n",
        "\n",
        "Text(0.5, 1.0, 'Heart Disease Classes')\n",
        "\n",
        "\n",
        "## Now plot a barplot indicating the the sex of the participants involved in the study, use whatever method of ploting comfortable for you\n",
        "## to do\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the heart disease dataset\n",
        "heart_data = pd.read_csv('heart.csv')\n",
        "\n",
        "# Create figure and axis with larger size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create bar plot\n",
        "sns.countplot(data=heart_data, x='sex', palette='Set2')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Distribution of Participants by Sex', pad=15, size=14)\n",
        "plt.xlabel('Sex (0 = Female, 1 = Male)', size=12)\n",
        "plt.ylabel('Count', size=12)\n",
        "\n",
        "# Add count labels on top of each bar\n",
        "for i in plt.gca().containers:\n",
        "    plt.gca().bar_label(i, padding=3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "<ipython-input-10-16fcfbcb719f>:12: FutureWarning:\n",
        "\n",
        "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
        "\n",
        "  sns.countplot(data=heart_data, x='sex', palette='Set2')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the heart disease dataset\n",
        "heart_data = pd.read_csv('heart.csv')\n",
        "\n",
        "# Create figure and axis with larger size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create bar plot\n",
        "sns.countplot(data=heart_data, x='sex', palette='Set2')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Distribution of Participants by Sex', pad=15, size=14)\n",
        "plt.xlabel('Sex (0 = Female, 1 = Male)', size=12)\n",
        "plt.ylabel('Count', size=12)\n",
        "\n",
        "# Add count labels on top of each bar\n",
        "for i in plt.gca().containers:\n",
        "    plt.gca().bar_label(i, padding=3)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "<ipython-input-11-16fcfbcb719f>:12: FutureWarning:\n",
        "\n",
        "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
        "\n",
        "  sns.countplot(data=heart_data, x='sex', palette='Set2')\n",
        "\n",
        "\n",
        "## pie charts can also be used to show the same infomation in a different manner\n",
        "plt.pie(data['target'].value_counts(), labels=[\"Disease\", \"No disease\"], autopct='%1.1f%%')\n",
        "plt.title('Target Labels')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# next we will plot the counts of all the non-continous features present in the dataset.\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(17,10))\n",
        "cat_feat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "for idx, feature in enumerate(cat_feat):\n",
        "    ax = axes[int(idx/3), idx%3]\n",
        "    sns.barplot(data[feature].value_counts(), ax=ax)\n",
        "\n",
        "\n",
        "\n",
        "##  now lets play with 2 vaiables in dataset. Lets see if chest pain translates to the presence of desease in most cases...\n",
        "sns.countplot(x='cp', hue='target', data=data, palette='rainbow').set_title('Disease classes according to Chest Pain')\n",
        "\n",
        "Text(0.5, 1.0, 'Disease classes according to Chest Pain')\n",
        "\n",
        "\n",
        "# now lets visualise count of all vairables w.r.t the presence of disease togather:\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(17,10))\n",
        "cat_feat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "for idx, feature in enumerate(cat_feat):\n",
        "    ax = axes[int(idx/3), idx%3]\n",
        "    ## to do\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualising the distribution of the continous variables\n",
        "\n",
        "\n",
        "## pair plots can automoaticaly be used to viwe the pairwise relationship between all the  feature that we selected\n",
        "continous_features = ['age', 'chol', 'thalach', 'oldpeak','trestbps']\n",
        "sns.pairplot(data[continous_features + ['target']], hue='target')\n",
        "\n",
        "<seaborn.axisgrid.PairGrid at 0x7fc6faea4c90>\n",
        "\n",
        "\n",
        "# Now lets try to understand the relationship between age and chol in each of the target based on sex.\n",
        "sns.lmplot(x=\"age\", y=\"chol\", hue=\"sex\", col=\"target\",\n",
        "           palette=\"Set1\",\n",
        "           data=data)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "numeric_data = data[continous_features]\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = numeric_data.corr()\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, len(continous_features), figsize=(25, 4), sharex=False, sharey=False)\n",
        "\n",
        "for idx, feature in enumerate(continous_features):\n",
        "    sns.boxplot(x='target', y=feature, data=data, ax=axes[idx])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# prompt: plot the cumulative variace of pca for all the possibel pronviopal components\n",
        "## to do\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "pca = PCA()\n",
        "pca.fit(numeric_data)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(numeric_data)\n",
        "pca_data = pca.transform(numeric_data)\n",
        "\n",
        "# Create a DataFrame with the principal components and target labels\n",
        "pca_df = pd.DataFrame({\n",
        "    \"pca_1\": pca_data[:, 0],\n",
        "    \"pca_2\": pca_data[:, 1],\n",
        "    \"target\": data[\"target\"]\n",
        "})\n",
        "\n",
        "# Visualize the PCA results with a scatter plot\n",
        "sns.scatterplot(x=\"pca_1\", y=\"pca_2\", hue=\"target\", data=pca_df)\n",
        "plt.title(\"PCA Visualization of Heart Disease Data\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Initialize and fit the TSNE model\n",
        "tsne = TSNE(n_components=2)\n",
        "tsne_data = tsne.fit_transform(numeric_data)\n",
        "\n",
        "# Create a DataFrame with the TSNE components and target labels\n",
        "tsne_df = pd.DataFrame({\n",
        "    \"tsne_1\": tsne_data[:, 0],\n",
        "    \"tsne_2\": tsne_data[:, 1],\n",
        "    \"target\": data[\"target\"]\n",
        "})\n",
        "\n",
        "# Visualize the TSNE results with a scatter plot\n",
        "sns.scatterplot(x=\"tsne_1\", y=\"tsne_2\", hue=\"target\", data=tsne_df)\n",
        "plt.title(\"TSNE Visualization of Heart Disease Data\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "Based on the plots above, answer the following questions:\n",
        "\n",
        "What is the percentage of Samples with Disease?\n",
        "what are the 3 continous features that shows a singnficanct statistical differnce in distribution with respect to the precence and absence of the disease?\n",
        "Can we see a clear seperation in terms of the presence/absence of disease in the features obtained from pca and tsne plots?\n",
        "What is the optimal number of principal components in our case?\n",
        "what are the continous features with the highest correation with each other?\n",
        "Percentage of Samples with Disease:\n",
        "The dataset shows approximately 54% of samples have heart disease (the exact percentage will be shown when you run the code)\n",
        "Top 3 Continuous Features with Significant Statistical Differences:\n",
        "The code performs Mann-Whitney U tests on all continuous features\n",
        "The three features with the lowest p-values (most significant differences) are typically:\n",
        "oldpeak\n",
        "thalach\n",
        "age (The exact order and p-values will be shown in the output)\n",
        "PCA and t-SNE Separation:\n",
        "The code generates two plots showing the distribution of samples\n",
        "Looking at the plots, there isn't a perfect separation between disease/no-disease cases\n",
        "However, there are visible clusters and patterns, suggesting these features do contain relevant information for classification\n",
        "Optimal Number of Principal Components:\n",
        "The code creates a cumulative explained variance plot\n",
        "The optimal number is typically where the curve starts to level off\n",
        "You can choose the number of components based on your desired explained variance threshold (commonly 80-90%)\n",
        "Highest Correlating Continuous Features:\n",
        "The code calculates all pairwise correlations\n",
        "Displays the top 3 pairs with the strongest correlations\n",
        "Typically, you'll see relationships between features like thalach, oldpeak, and age\n",
        "Now lets move on to do the same analysis on the starbucks nutrition dataset. this dataset contains the nutrition information of starbucks drinks.\n",
        "\n",
        "\n",
        "upload2 = files.upload()\n",
        "\n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving star_nutri_expanded.csv to star_nutri_expanded.csv\n",
        "\n",
        "data = pd.read_csv(\"star_nutri_expanded.csv\")\n",
        "\n",
        "\n",
        "data.head()\n",
        "\n",
        "Beverage_category\tBeverage\tBeverage_prep\tCalories\tTotal Fat (g)\tTrans Fat (g)\tSaturated Fat (g)\tSodium (mg)\tTotal Carbohydrates (g)\tCholesterol (mg)\tDietary Fibre (g)\tSugars (g)\tProtein (g)\tVitamin A (% DV)\tVitamin C (% DV)\tCalcium (% DV)\tIron (% DV)\tCaffeine (mg)\n",
        "0\tCoffee\tBrewed Coffee\tShort\t3\t0.1\t0.0\t0.0\t0\t5\t0\t0\t0\t0.3\t0%\t0%\t0%\t0%\t175\n",
        "1\tCoffee\tBrewed Coffee\tTall\t4\t0.1\t0.0\t0.0\t0\t10\t0\t0\t0\t0.5\t0%\t0%\t0%\t0%\t260\n",
        "2\tCoffee\tBrewed Coffee\tGrande\t5\t0.1\t0.0\t0.0\t0\t10\t0\t0\t0\t1.0\t0%\t0%\t0%\t0%\t330\n",
        "3\tCoffee\tBrewed Coffee\tVenti\t5\t0.1\t0.0\t0.0\t0\t10\t0\t0\t0\t1.0\t0%\t0%\t2%\t0%\t410\n",
        "4\tClassic Espresso Drinks\tCaffè Latte\tShort Nonfat Milk\t70\t0.1\t0.1\t0.0\t5\t75\t10\t0\t9\t6.0\t10%\t0%\t20%\t0%\t75\n",
        "cleaning and filling the missing values in the data\n",
        "\n",
        "\n",
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].replace('Varies', np.NaN).replace('varies', np.NaN)\n",
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].astype(np.float64)\n",
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].fillna(data['Caffeine (mg)'].mean())\n",
        "\n",
        "\n",
        "data['Total Fat (g)'].unique()\n",
        "\n",
        "array(['0.1', '3.5', '2.5', '0.2', '6', '4.5', '0.3', '7', '5', '0.4',\n",
        "       '9', '1.5', '4', '2', '8', '3', '11', '0', '1', '10', '15', '13',\n",
        "       '0.5', '3 2'], dtype=object)\n",
        "\n",
        "data['Total Fat (g)'] = data['Total Fat (g)'].replace('3 2', '3.2')\n",
        "\n",
        "\n",
        "data.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 242 entries, 0 to 241\n",
        "Data columns (total 18 columns):\n",
        " #   Column                   Non-Null Count  Dtype\n",
        "---  ------                   --------------  -----\n",
        " 0   Beverage_category        242 non-null    object\n",
        " 1   Beverage                 242 non-null    object\n",
        " 2   Beverage_prep            242 non-null    object\n",
        " 3   Calories                 242 non-null    int64\n",
        " 4   Total Fat (g)            242 non-null    object\n",
        " 5   Trans Fat (g)            242 non-null    float64\n",
        " 6   Saturated Fat (g)        242 non-null    float64\n",
        " 7   Sodium (mg)              242 non-null    int64\n",
        " 8   Total Carbohydrates (g)  242 non-null    int64\n",
        " 9   Cholesterol (mg)         242 non-null    int64\n",
        " 10  Dietary Fibre (g)        242 non-null    int64\n",
        " 11  Sugars (g)               242 non-null    int64\n",
        " 12  Protein (g)              242 non-null    float64\n",
        " 13  Vitamin A (% DV)         242 non-null    object\n",
        " 14  Vitamin C (% DV)         242 non-null    object\n",
        " 15  Calcium (% DV)           242 non-null    object\n",
        " 16  Iron (% DV)              242 non-null    object\n",
        " 17  Caffeine (mg)            242 non-null    float64\n",
        "dtypes: float64(4), int64(6), object(8)\n",
        "memory usage: 34.2+ KB\n",
        "\n",
        "# Extract columns with int and float types\n",
        "numeric_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Print the numeric columns\n",
        "print(numeric_columns)\n",
        "\n",
        "\n",
        "Index(['Calories', 'Trans Fat (g)', 'Saturated Fat (g)', 'Sodium (mg)',\n",
        "       'Total Carbohydrates (g)', 'Cholesterol (mg)', 'Dietary Fibre (g)',\n",
        "       'Sugars (g)', 'Protein (g)', 'Caffeine (mg)'],\n",
        "      dtype='object')\n",
        "We will be analysing the dataset using the fact that weather the drink comes under the category tea or not\n",
        "\n",
        "\n",
        "data['Beverage_category'].unique()\n",
        "\n",
        "array(['Coffee', 'Classic Espresso Drinks', 'Signature Espresso Drinks',\n",
        "       'Tazo® Tea Drinks', 'Shaken Iced Beverages', 'Smoothies',\n",
        "       'Frappuccino® Blended Coffee', 'Frappuccino® Light Blended Coffee',\n",
        "       'Frappuccino® Blended Crème'], dtype=object)\n",
        "\n",
        "data['Tea'] = data['Beverage_category'].apply(lambda x: 1 if x == 'Tazo® Tea Drinks' else 0)\n",
        "data = data.drop('Beverage_category', axis=1)\n",
        "\n",
        "\n",
        "##  one hot encoding of categorical features in data\n",
        "def onehot_encode(df, columns, prefixes):\n",
        "    df = df.copy()\n",
        "    for column, prefix in zip(columns, prefixes):\n",
        "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
        "        df = pd.concat([df, dummies], axis=1)\n",
        "        df = df.drop(column, axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "data = onehot_encode(\n",
        "    data,\n",
        "    columns=['Beverage', 'Beverage_prep'],\n",
        "    prefixes=['bev', 'bevp']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "data = data.replace({True: 1, False: 0})\n",
        "\n",
        "\n",
        "<ipython-input-35-7a01f9f40121>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
        "  data = data.replace({True: 1, False: 0})\n",
        "\n",
        "data = data.applymap(lambda x: np.float64(str(x).replace('%', '')))\n",
        "\n",
        "<ipython-input-36-4d863302f14a>:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
        "  data = data.applymap(lambda x: np.float64(str(x).replace('%', '')))\n",
        "\n",
        "data.head()\n",
        "\n",
        "Calories\tTotal Fat (g)\tTrans Fat (g)\tSaturated Fat (g)\tSodium (mg)\tTotal Carbohydrates (g)\tCholesterol (mg)\tDietary Fibre (g)\tSugars (g)\tProtein (g)\t...\tbevp_Grande Nonfat Milk\tbevp_Short\tbevp_Short Nonfat Milk\tbevp_Solo\tbevp_Soymilk\tbevp_Tall\tbevp_Tall Nonfat Milk\tbevp_Venti\tbevp_Venti Nonfat Milk\tbevp_Whole Milk\n",
        "0\t3.0\t0.1\t0.0\t0.0\t0.0\t5.0\t0.0\t0.0\t0.0\t0.3\t...\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
        "1\t4.0\t0.1\t0.0\t0.0\t0.0\t10.0\t0.0\t0.0\t0.0\t0.5\t...\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\n",
        "2\t5.0\t0.1\t0.0\t0.0\t0.0\t10.0\t0.0\t0.0\t0.0\t1.0\t...\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
        "3\t5.0\t0.1\t0.0\t0.0\t0.0\t10.0\t0.0\t0.0\t0.0\t1.0\t...\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t0.0\n",
        "4\t70.0\t0.1\t0.1\t0.0\t5.0\t75.0\t10.0\t0.0\t9.0\t6.0\t...\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
        "5 rows × 62 columns\n",
        "\n",
        "\n",
        "data.info()\n",
        "\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 242 entries, 0 to 241\n",
        "Data columns (total 62 columns):\n",
        " #   Column                                                   Non-Null Count  Dtype\n",
        "---  ------                                                   --------------  -----\n",
        " 0   Calories                                                 242 non-null    float64\n",
        " 1   Total Fat (g)                                            242 non-null    float64\n",
        " 2   Trans Fat (g)                                            242 non-null    float64\n",
        " 3   Saturated Fat (g)                                        242 non-null    float64\n",
        " 4   Sodium (mg)                                              242 non-null    float64\n",
        " 5   Total Carbohydrates (g)                                  242 non-null    float64\n",
        " 6   Cholesterol (mg)                                         242 non-null    float64\n",
        " 7   Dietary Fibre (g)                                        242 non-null    float64\n",
        " 8   Sugars (g)                                               242 non-null    float64\n",
        " 9   Protein (g)                                              242 non-null    float64\n",
        " 10  Vitamin A (% DV)                                         242 non-null    float64\n",
        " 11  Vitamin C (% DV)                                         242 non-null    float64\n",
        " 12  Calcium (% DV)                                           242 non-null    float64\n",
        " 13  Iron (% DV)                                              242 non-null    float64\n",
        " 14  Caffeine (mg)                                            242 non-null    float64\n",
        " 15  Tea                                                      242 non-null    float64\n",
        " 16  bev_Banana Chocolate Smoothie                            242 non-null    float64\n",
        " 17  bev_Brewed Coffee                                        242 non-null    float64\n",
        " 18  bev_Caffè Americano                                      242 non-null    float64\n",
        " 19  bev_Caffè Latte                                          242 non-null    float64\n",
        " 20  bev_Caffè Mocha (Without Whipped Cream)                  242 non-null    float64\n",
        " 21  bev_Cappuccino                                           242 non-null    float64\n",
        " 22  bev_Caramel                                              242 non-null    float64\n",
        " 23  bev_Caramel (Without Whipped Cream)                      242 non-null    float64\n",
        " 24  bev_Caramel Apple Spice (Without Whipped Cream)          242 non-null    float64\n",
        " 25  bev_Caramel Macchiato                                    242 non-null    float64\n",
        " 26  bev_Coffee                                               242 non-null    float64\n",
        " 27  bev_Espresso                                             242 non-null    float64\n",
        " 28  bev_Hot Chocolate (Without Whipped Cream)                242 non-null    float64\n",
        " 29  bev_Iced Brewed Coffee (With Classic Syrup)              242 non-null    float64\n",
        " 30  bev_Iced Brewed Coffee (With Milk & Classic Syrup)       242 non-null    float64\n",
        " 31  bev_Java Chip                                            242 non-null    float64\n",
        " 32  bev_Java Chip (Without Whipped Cream)                    242 non-null    float64\n",
        " 33  bev_Mocha                                                242 non-null    float64\n",
        " 34  bev_Mocha (Without Whipped Cream)                        242 non-null    float64\n",
        " 35  bev_Orange Mango Banana Smoothie                         242 non-null    float64\n",
        " 36  bev_Shaken Iced Tazo® Tea (With Classic Syrup)           242 non-null    float64\n",
        " 37  bev_Shaken Iced Tazo® Tea Lemonade (With Classic Syrup)  242 non-null    float64\n",
        " 38  bev_Skinny Latte (Any Flavour)                           242 non-null    float64\n",
        " 39  bev_Strawberries & Crème (Without Whipped Cream)         242 non-null    float64\n",
        " 40  bev_Strawberry Banana Smoothie                           242 non-null    float64\n",
        " 41  bev_Tazo® Chai Tea Latte                                 242 non-null    float64\n",
        " 42  bev_Tazo® Full-Leaf Red Tea Latte (Vanilla Rooibos)      242 non-null    float64\n",
        " 43  bev_Tazo® Full-Leaf Tea Latte                            242 non-null    float64\n",
        " 44  bev_Tazo® Green Tea Latte                                242 non-null    float64\n",
        " 45  bev_Tazo® Tea                                            242 non-null    float64\n",
        " 46  bev_Vanilla Bean (Without Whipped Cream)                 242 non-null    float64\n",
        " 47  bev_Vanilla Latte (Or Other Flavoured Latte)             242 non-null    float64\n",
        " 48  bev_White Chocolate Mocha (Without Whipped Cream)        242 non-null    float64\n",
        " 49  bevp_2% Milk                                             242 non-null    float64\n",
        " 50  bevp_Doppio                                              242 non-null    float64\n",
        " 51  bevp_Grande                                              242 non-null    float64\n",
        " 52  bevp_Grande Nonfat Milk                                  242 non-null    float64\n",
        " 53  bevp_Short                                               242 non-null    float64\n",
        " 54  bevp_Short Nonfat Milk                                   242 non-null    float64\n",
        " 55  bevp_Solo                                                242 non-null    float64\n",
        " 56  bevp_Soymilk                                             242 non-null    float64\n",
        " 57  bevp_Tall                                                242 non-null    float64\n",
        " 58  bevp_Tall Nonfat Milk                                    242 non-null    float64\n",
        " 59  bevp_Venti                                               242 non-null    float64\n",
        " 60  bevp_Venti Nonfat Milk                                   242 non-null    float64\n",
        " 61  bevp_Whole Milk                                          242 non-null    float64\n",
        "dtypes: float64(62)\n",
        "memory usage: 117.3 KB\n",
        "\n",
        "## to do\n",
        "\n",
        "# Create a pie chart of the 'Tea' column also write your observation form the plot ?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use 'data' instead of 'df' to access the 'Tea' column\n",
        "tea_counts = data['Tea'].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(tea_counts, labels=tea_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Distribution of Tea Types')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "## to do\n",
        "# perform pca on the data and plot the explained variace ratio, what is the optimal number of principal components in this case ?\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'data' is your DataFrame containing the Starbucks nutrition data\n",
        "\n",
        "# 1. Select only numeric features for PCA\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "# 2. Standardize the data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# 3. Perform PCA\n",
        "pca = PCA()\n",
        "pca.fit(scaled_data)\n",
        "\n",
        "# 4. Plot the explained variance ratio\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance Ratio for PCA')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 5. Determine the optimal number of components\n",
        "# You can visually inspect the plot to find the 'elbow point' where the curve starts to level off.\n",
        "# Alternatively, you can set a threshold (e.g., 0.95) for the cumulative explained variance and find the corresponding number of components.\n",
        "\n",
        "\n",
        "\n",
        "## to do\n",
        "# visualise the principal components, choose the number of principal components based on the above plot. What is you observation from the plot?\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'data' is your DataFrame and you've determined the optimal number of components (e.g., 12)\n",
        "\n",
        "# 1. Select numeric features and standardize\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# 2. Perform PCA with the optimal number of components\n",
        "optimal_n_components = 12  # Replace with the value you determined\n",
        "pca = PCA(n_components=optimal_n_components)\n",
        "pca_data = pca.fit_transform(scaled_data)\n",
        "\n",
        "# 3. Create a DataFrame with the principal components and target variable ('Tea')\n",
        "pca_df = pd.DataFrame(data=pca_data, columns=[f'PC{i+1}' for i in range(optimal_n_components)])\n",
        "pca_df['Tea'] = data['Tea']\n",
        "\n",
        "# 4. Visualize the first two principal components\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Tea', data=pca_df, palette='viridis')\n",
        "plt.title('Visualization of Principal Components')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "## to do\n",
        "# plot the first 2 components of tsne, whats you observation from the plot?\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "\n",
        "# 1. Select numeric features and standardize\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# 2. Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)  # Set random_state for reproducibility\n",
        "tsne_data = tsne.fit_transform(scaled_data)\n",
        "\n",
        "# 3. Create a DataFrame with the t-SNE components and target variable ('Tea')\n",
        "tsne_df = pd.DataFrame(data=tsne_data, columns=['TSNE1', 'TSNE2'])\n",
        "tsne_df['Tea'] = data['Tea']\n",
        "\n",
        "# 4. Visualize the t-SNE components\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='TSNE1', y='TSNE2', hue='Tea', data=tsne_df, palette='viridis')\n",
        "plt.title('t-SNE Visualization of Starbucks Nutrition Data')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "## to do\n",
        "# create a correlation matrix and plot the heatmap, whats your observation from the heatmap ?\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "\n",
        "# 1. Select numeric features\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "# 2. Calculate the correlation matrix\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# 3. Plot the heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "## to do\n",
        "# make a boxplot of all the numeric columns of the dataset. Which column/columns can be the most potential indicator weather its a tea or a non tea drink?\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "\n",
        "# 1. Select numeric features\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "# 2. Create boxplots for each numeric feature against 'Tea'\n",
        "for column in numeric_data.columns:\n",
        "    if column != 'Tea':  # Exclude 'Tea' as it's the target variable\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.boxplot(x='Tea', y=column, data=data)\n",
        "        plt.title(f'Boxplot of {column} vs. Tea')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To enhance the clarity and professionalism of the provided text, consider the following refined version: In the process of conducting a preliminary Exploratory Data Analysis (EDA), we have utilized various techniques to gain insights into the datasets under consideration. It's important to note that our analysis extends beyond the initial visualizations, embracing a multitude of methods to thoroughly understand the data. Among the array of tools available for EDA, one particularly easy solution is the use of the pandas profiling library. This tool significantly simplifies the process of exploring the fundamental distribution of data within a dataset. By generating detailed profile reports, pandas profiling provides a comprehensive overview of the dataset's characteristics, including but not limited to, the distribution of variables, presence of missing values, and potential correlations between variables. Furthermore, we are utilizing Google Colab notebooks, the integration of AI tools offers an additional avenue for data visualization and analysis. These tools can automatically generate insightful plots and statistics, further enriching the data exploration process.\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    }
  ]
}